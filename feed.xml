<feed xmlns="http://www.w3.org/2005/Atom"> <id>https://hetong07.github.io</id><title>hetong07</title><subtitle>Opinions are my own.</subtitle> <updated>2021-01-19T09:36:25+08:00</updated> <author> <name>hetong07</name> <uri>https://hetong07.github.io</uri> </author><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="https://hetong07.github.io" rel="alternate" type="text/html" /> <generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator> <rights> © 2021 hetong07 </rights> <icon>/assets/img/favicons/favicon.ico</icon> <logo>/assets/img/favicons/favicon-96x96.png</logo> <entry><title>GPU Scheduling for ML workload</title><link href="https://hetong07.github.io/posts/GPU-Scheduling/" rel="alternate" type="text/html" title="GPU Scheduling for ML workload" /><published>2021-01-16T06:00:00+08:00</published> <updated>2021-01-19T09:35:44+08:00</updated> <id>https://hetong07.github.io/posts/GPU-Scheduling/</id> <content src="https://hetong07.github.io/posts/GPU-Scheduling/" /> <author> <name>hetong07</name> </author> <category term="Blogging" /> <category term="Technical" /> <summary> GPU Scheduling for ML workload GPU scheduling topic is very popular in both academia and industry. Previous focus is on distributed ML system, and key of those researches are the fact in ML training, the parameters do not require strong consistency. The solution is the Parameter server. Therefore, the key for scheduling multiple ML tasks within one cluster is also the ML properties. Workload ... </summary> </entry> <entry><title>Caladan interference mitigation</title><link href="https://hetong07.github.io/posts/caladan/" rel="alternate" type="text/html" title="Caladan interference mitigation" /><published>2021-01-15T07:35:00+08:00</published> <updated>2021-01-15T08:36:29+08:00</updated> <id>https://hetong07.github.io/posts/caladan/</id> <content src="https://hetong07.github.io/posts/caladan/" /> <author> <name>hetong07</name> </author> <category term="Blogging" /> <category term="Technical" /> <summary> Caladan interference mitigation People are always focus how to schedule tasks within a cluster or across cluster, but less focus on scheduling tasks within a machine, because we usually think the Linux scheduler is highly optimized and too complicated to change. This paper Caladan: Mitigating Interference at Microsecond Timescales, however, focus on how to improve scheduling efficiency on sin... </summary> </entry> <entry><title>Basic Understanding of LevelDB</title><link href="https://hetong07.github.io/posts/Basic-Understanding-of-LevelDB/" rel="alternate" type="text/html" title="Basic Understanding of LevelDB" /><published>2020-06-07T14:22:00+08:00</published> <updated>2020-06-07T14:22:00+08:00</updated> <id>https://hetong07.github.io/posts/Basic-Understanding-of-LevelDB/</id> <content src="https://hetong07.github.io/posts/Basic-Understanding-of-LevelDB/" /> <author> <name>hetong07</name> </author> <category term="Blogging" /> <category term="Technical" /> <summary> LevelDB is the open-sourced Google BigTable implementaion, and its coding style is nice for amateurs to follow. This post presents my understands of the LevelDB and some details of its implementaion. With those components below, one can simulate how LevelDB works in situations, such as, open, read, write, snapshot, failure recovery. Table file structure (levels) The underlying table data struc... </summary> </entry> <entry><title>Paxos RSM</title><link href="https://hetong07.github.io/posts/Paxos-RSM/" rel="alternate" type="text/html" title="Paxos RSM" /><published>2020-05-28T06:09:00+08:00</published> <updated>2020-05-28T06:09:00+08:00</updated> <id>https://hetong07.github.io/posts/Paxos-RSM/</id> <content src="https://hetong07.github.io/posts/Paxos-RSM/" /> <author> <name>hetong07</name> </author> <category term="Blogging" /> <category term="Technical" /> <summary> Replicated State Machine (RSM) [1] talks about the theory of RSM. The core idea if the RSM is straightforward: replicate the state machine (SM) on different processes/servers, and as lone as the input to those SMs are the same, all the RMs should have the same status. The key to this RSM architecture is how to keep the input sequence to all SMs are the same. [1] decompose the requirement of the... </summary> </entry> <entry><title>Paxos and Raft</title><link href="https://hetong07.github.io/posts/paxos-and-raft/" rel="alternate" type="text/html" title="Paxos and Raft" /><published>2020-05-26T10:42:00+08:00</published> <updated>2020-05-26T10:42:00+08:00</updated> <id>https://hetong07.github.io/posts/paxos-and-raft/</id> <content src="https://hetong07.github.io/posts/paxos-and-raft/" /> <author> <name>hetong07</name> </author> <category term="Blogging" /> <category term="Technical" /> <summary> This is not a complete explanation of the Paxos and the Raft, but just some thoughts about some corner cases. Livelock and leader in the Paxos The basic paxos algorith works well but has a livelock issue: two proposers may each grow the instance number to infinite but no one can proceed. To solve this problem, the author proposes the notion of distinctive proposer, which acts as the leader to... </summary> </entry> </feed>
